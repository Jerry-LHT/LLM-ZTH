# LLM

## 一、LLM基础概念：GPT与Transformer

### 1.1 GPT含义与核心特性
GPT全称为“Generative Pretrained Transformer”，三个关键词精准定义模型核心能力，具体拆解如下：
- **Generative（生成式）**：核心功能是“生成新文本”，而非仅做分类、匹配等静态任务。例如输入“写一段关于春天的短诗”，模型能直接输出完整诗句，而非仅判断“春天”相关主题。
- **Pretrained（预训练）**：模型训练分两步走。第一步通过海量通用数据（如全网公开文本、书籍等）完成“预训练”，掌握语言语法、逻辑、常识；第二步可通过“微调”（Fine-tuning），用特定领域数据（如医疗文献、法律条文）适配专项任务，降低训练成本。
- **Transformer（Transformer架构）**：模型的“骨架”，是支撑LLM实现复杂语言理解与生成的核心神经网络结构，也是当前AI技术（含多模态）爆发的底层基础。

### 1.2 Transformer的适用范围与LLM核心逻辑

#### 1.2.1 Transformer的多任务能力
Transformer并非仅服务于LLM，而是可覆盖多模态任务，具体场景包括：
- 文本领域：机器翻译（如中英互译）、文本生成（ChatGPT、文案创作）、文本摘要；
- 语音领域：语音转文字（转录会议记录）、文字转语音（生成合成语音）；
- 图像领域：文本生成图像（Midjourney、DALL-E）、图像描述生成（给图片写文字说明）。

#### 1.2.2 LLM的核心工作逻辑
以ChatGPT为代表的LLM，本质是“预测下一个Token”的循环模型，具体流程为：
1. **输入触发**：接收用户输入的“种子文本”（如“解释什么是LLM”），该文本包含上下文信息；
2. **概率预测**：模型分析输入文本，输出“下一个可能出现的Token”的概率分布（Token可是完整单词、词根、标点，如“LLM”“是”“大”等）；
3. **循环生成**：从概率分布中“采样”一个Token（如“大”），拼接至原输入文本；再以“解释什么是LLM大”为新输入，重复“预测-采样-拼接”步骤，直至生成连贯、完整的回复。


## 二、Transformer数据处理全流程

### 2.1 输入端：Tokenization（分词）与向量嵌入

#### 2.1.1 Tokenization（分词）：将输入转为模型可识别单元
- **核心作用**：把人类可读的文本（或图像、语音）拆解为模型能处理的最小单元“Token”，解决“文本是离散符号，模型需连续数值”的矛盾。
- **Token类型细分**：
  - 文本Token：并非仅完整单词，还包括词根、前缀/后缀、标点。例如“unhappiness”可能拆为“un”（前缀）、“happy”（词根）、“ness”（后缀）；“Hello!”拆为“Hello”“!”；
  - 多模态Token：图像拆为“固定大小的像素块”（如16×16像素），语音拆为“固定时长的音频帧”（如20ms/帧）。
- **词汇表（Vocabulary）**：模型有预设“词汇表”，包含所有可识别的Token，例如GPT-3的词汇表规模为50257个Token，若输入文本含词汇表外的字符（如生僻字、特殊符号），会用“未知Token”（如“<unk>”）替代。

#### 2.1.2 向量嵌入（Embedding）：给Token赋予“语义数值”
- **核心目标**：将离散的Token转换为连续的“向量”（即一组数字，如[0.2, 1.5, -0.8,...]），使模型能通过数学运算（如加减、点积）理解Token的语义关系。
- **关键组件：嵌入矩阵（Embedding Matrix）**：
  - 矩阵结构：维度为“词汇表大小×嵌入维度”。以GPT-3为例，词汇表50257个Token，嵌入维度12288，因此嵌入矩阵参数数量为50257×12288≈6.7亿；
  - 学习过程：初始时矩阵数值随机，模型通过训练不断调整——语义越相似的Token，对应向量在“高维空间”中的距离越近（如“猫”和“狗”的向量距离，远小于“猫”和“汽车”）。
- **语义空间的核心特性**：高维向量空间中，“特定方向”对应明确的语义属性，典型案例包括：
  - 性别属性：“woman（女人）- man（男人）”的向量差，与“queen（女王）- king（国王）”的向量差方向接近，可通过“king + (woman - man)”计算出“queen”的近似向量；
  - 地域/人物关联：“Italy（意大利）- Germany（德国）+ Hitler（希特勒）”的向量运算结果，与“Mussolini（墨索里尼）”的向量高度接近；
  - 数量属性：“cats（猫，复数）- cat（猫，单数）”的向量差，与“dogs（狗，复数）- dog（狗，单数）”“books（书，复数）- book（书，单数）”的向量差方向一致，可用于区分单复数语义。

### 2.2 中间层：Transformer的核心计算模块
输入向量需依次经过“注意力块（Attention Block）”和“多层感知机（MLP/Feed-Forward Layer）”，且该过程会“多层堆叠”（如GPT-3有96层），逐步优化向量的语义表达。

#### 2.2.1 注意力块（Attention Block）：让Token“理解上下文”
- **核心功能**：实现“Token间的信息交互”，让每个Token能“关注”上下文里与自己相关的Token，从而理解自身在语境中的具体含义。
  - 示例：“model”在“machine learning model（机器学习模型）”中表示“模型”，在“fashion model（时尚模特）”中表示“模特”；注意力块会通过计算“model”与周围Token（如“machine learning”“fashion”）的向量相似度，调整“model”的向量，使其匹配当前语境语义。
- **关键计算：点积（Dot Product）**：用于衡量两个向量的“语义相似度”。计算逻辑是“对应元素相乘后求和”，结果为正时，向量方向越接近（语义越相似）；结果为0时，向量垂直（语义无关）；结果为负时，向量方向相反（语义对立）。

#### 2.2.2 多层感知机（MLP/Feed-Forward Layer）：提取复杂语义特征
- **核心功能**：对每个向量进行“独立的特征转换”，不涉及Token间的信息交换（所有向量并行处理），相当于给每个Token的语义“做精细化加工”。
  - 作用类比：可理解为对每个Token的向量“提问”——“这个Token是否与‘技术’相关？是否与‘时间’相关？是否描述‘情感’？”，再根据“回答”（通过线性变换、激活函数计算）调整向量数值，提取更复杂的语义特征（如从“苹果”的基础语义，到“红色的、可食用的、产自山东的苹果”的具体语义）。
- **补充：归一化（Normalization）**：中间层每处理完一个模块（注意力块/MLP），会进行“层归一化（Layer Normalization）”，防止向量数值过大或过小（如出现10000、-10000这类极端值），保证模型训练稳定。

### 2.3 输出端：生成Token概率分布

#### 2.3.1 关键组件：解嵌入矩阵（Unembedding Matrix）
- **核心作用**：将中间层输出的“最后一个向量”（因LLM是“预测下一个Token”，需聚焦序列末尾的语义），映射为“与词汇表规模一致的数值列表”（如GPT-3对应50257个数值），这些未归一化的数值称为“Logits”（对数几率）。
- **矩阵特性**：与嵌入矩阵“对称”——嵌入矩阵是“Token→向量”（维度50257×12288），解嵌入矩阵是“向量→Logits”（维度12288×50257），因此参数数量同样约6.7亿。

#### 2.3.2 核心函数：Softmax——将Logits转为概率分布
- **功能目标**：把任意数值的Logits（可正可负，如“苹果”的Logits=5，“汽车”的Logits=-2），转换为“合法的概率分布”——每个Token的概率值在0~1之间，且所有Token概率总和为1，方便模型“采样”下一个Token。
- **计算步骤**：
  1. 指数化：对每个Logits计算“e的Logits次方”（e^Logits），确保所有数值变为正数（因e的任何次幂都为正）；
  2. 归一化：计算所有“指数化结果”的总和，再用每个“指数化结果”除以该总和，得到对应Token的概率。
- **重要参数：温度（Temperature）**：用于调整概率分布的“随机性”，直接影响生成文本的风格，具体效果如下：
  - 低温度（T<1，如T=0.3）：放大高概率Token的优势，抑制低概率Token。生成文本更稳定、严谨，但可能“刻板”（如T=0时，仅选概率最高的Token，生成“从前有座山，山里有座庙，庙里有个老和尚”这类固定套路）；
  - 高温度（T>1，如T=1.5）：降低高概率Token的优势，提升低概率Token的权重。生成文本更灵活、有创意，但可能“逻辑混乱”（如T=1.8时，生成“从前有个来自韩国的年轻网络艺术家，她用云朵做颜料，在月亮上画代码”，后续可能偏离主题）；
  - 实践限制：多数LLM API（如GPT-3）限制温度最大值为2，避免生成完全无意义的内容（如“从前有个#%￥&，它在*@￥星球吃$%^”）。


## 三、LLM模型训练与关键参数

### 3.1 核心训练算法：反向传播（Backpropagation）
- **核心逻辑**：模型通过“预测误差→反向调参”的循环，逐步学会“准确预测下一个Token”，具体流程为：
  1. 计算误差：用“交叉熵损失函数”，比较模型预测的Token概率分布，与“真实文本中的下一个Token”（如输入“我爱吃”，真实下一个Token是“苹果”）的差距，差距越大，误差越高；
  2. 反向调参：从输出层往输入层反向计算，调整所有矩阵的参数（如嵌入矩阵、注意力块权重矩阵、解嵌入矩阵），减小下一次预测的误差；
  3. 循环迭代：重复“输入文本→预测→算误差→调参数”步骤，直至模型在训练数据上的误差稳定在较低水平。

- **训练效率优化**：训练时并非仅用“序列最后一个向量”预测下一个Token，而是用“所有中间向量”同时预测对应位置的下一个Token。例如输入“我爱吃苹果”，用“我”的向量预测“爱”，用“爱”的向量预测“吃”，用“吃”的向量预测“苹果”——一次输入生成多个训练样本，大幅提升训练效率。

### 3.2 模型参数规模与构成（以GPT-3为例）
- **总参数规模**：约1750亿，这些参数均以“矩阵”形式存储，共约2.8万个矩阵，分8类（如注意力块的Q/K/V矩阵、MLP的线性变换矩阵等）。
- **参数构成明细**：
  1. 嵌入矩阵：约6.7亿（占比0.38%）；
  2. 解嵌入矩阵：约6.7亿（占比0.38%）；
  3. 中间层矩阵（注意力块+MLP）：约1750-6.7-6.7=1736.6亿（占比99.24%）——是参数的核心构成，直接决定模型的语义理解与生成能力。

### 3.3 关键限制：上下文窗口（Context Size）
- **定义**：模型一次能处理的“最大Token数量”，决定了模型能“记住”的上下文长度（即能关联的历史对话/文本范围）。
- **典型案例**：GPT-3的上下文窗口为2048个Token，对应文本长度约为：英文1500-2000个单词（每个Token约4个英文字符），中文2500-3000个汉字（每个Token约1.5个中文字符）。
- **实际影响**：若对话/文本长度超过上下文窗口，模型会“遗忘”早期内容。例如早期ChatGPT在10轮以上长对话后，可能忘记用户最初说的“我喜欢咖啡”，因为早期对话的Token已被“挤出”上下文窗口。

